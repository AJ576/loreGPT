{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B899VZm9uyNm",
        "outputId": "915d60d4-a5d2-4049-87cf-0b2026f4a000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.12.0-cp311-cp311-win_amd64.whl.metadata (5.2 kB)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement faiss-gpu-cu12 (from versions: none)\n",
            "ERROR: No matching distribution found for faiss-gpu-cu12\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu faiss-gpu-cu12 sentence_transformers transformers accelerate sentencepiece numpy pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ShT4eVSnucKf"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import json\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yK5_11LGv9f_"
      },
      "outputs": [],
      "source": [
        "INDEX_FILE = \"faiss_index.index\"\n",
        "META_FILE = \"meta.jsonl\"\n",
        "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "def load_metadata():\n",
        "    metadata = []\n",
        "    with open(META_FILE, \"r\") as f:\n",
        "        for line in f:\n",
        "            metadata.append(json.loads(line))\n",
        "    return metadata\n",
        "\n",
        "def search(query, top_k=5):\n",
        "    model = SentenceTransformer(MODEL_NAME)\n",
        "    query_vector = model.encode(query).astype(\"float32\").reshape(1, -1)\n",
        "    query_vector /= np.linalg.norm(query_vector, axis=1, keepdims=True)  # Normalize for cosine sim\n",
        "\n",
        "    index = faiss.read_index(INDEX_FILE)\n",
        "    metadata = load_metadata()\n",
        "\n",
        "    D, I = index.search(query_vector, top_k)\n",
        "    results = []\n",
        "\n",
        "    for idx in I[0]:\n",
        "        item = metadata[idx]\n",
        "        results.append({\n",
        "            \"doc_id\": item[\"doc_id\"],\n",
        "            \"chunk_index\": item[\"chunk_index\"],\n",
        "            \"text\": item[\"text\"]\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     query = input(\"Enter your question: \")\n",
        "#     results = search(query)\n",
        "\n",
        "#     print(\"\\nTop matching chunks:\\n\")\n",
        "#     for i, r in enumerate(results, 1):\n",
        "#         print(f\"[{i}] {r['text']}\\n\")\n",
        "#     print(\"\\nSearch completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bb3c336092af4d609f60cdb3238fdd2d",
            "be4137738f1c41bd8d68e2f6300d297d",
            "e2888432c11c46579441ccdbf1b26e90",
            "8d778b919efa40a993784a9ed5e8f9e0",
            "e3d0155e67f24965b811bf278e59448e",
            "91a4dbdddb22401e918b3ba07c08da7e",
            "d03f2a1ed5e54b25aaa2e802c15ccd66",
            "af2d99f519f84cb280214897588ff531",
            "7ddc309f8cb84347887738050acf8ab6",
            "66195108f7e44358bf957758e1a216ea",
            "3ba7077c5c064699b894222d65024406"
          ]
        },
        "id": "tDv01ZZqwjPq",
        "outputId": "f4947925-ad19-46fd-f4f7-a8dec53f5470"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--microsoft--phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Fetching 2 files: 100%|██████████| 2/2 [04:49<00:00, 144.76s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.09s/it]\n",
            "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load the LLM for generation\n",
        "llm_model_id = \"microsoft/phi-3-mini-4k-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate_answer(context_chunks, question):\n",
        "    context = \"\\n\\n\".join([chunk['text'] for chunk in context_chunks])\n",
        "    prompt = f\"\"\"You are a helpful assistant. Answer the following question using only the given context. Be brief and factual.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=200, do_sample=True, temperature=0.2,top_p=0.9)\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    answer = decoded.split(\"Answer:\")[-1].strip()\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eRT3bepi0l_m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top matching chunks:\n",
            "\n",
            "[1] Kaladin is the focus character of the novel. At the beginning of his story, he is a squadleader in Amaram's army. His storyline then cuts to his time as a slave. He is sold to  Sadeas's warcamp, where he is placed in Bridge Four, and made to run headlong into enemy fire with the rest of his bridgecrew to give the army a way to cross the chasms as well as drawing enemy arrows away from troops. After a period of despair, Kaladin works to improve the life of his bridgecrew. He trains them so that the bridge runs won't tire them out so much, saves the lives of injured bridgemen, and slowly gets them to start caring again, and to see themselves as soldiers. Kaladin also plans to find a way to escape from Sadeas's army.\n",
            "Kaladin faces the internal struggles of his inability to save those around him and his distrust of any lighteyes.\n",
            "As the focus character of The Way of Kings, Kaladin's past is viewed through the use of flashbacks. The flashbacks show his childhood and his surgeon apprenticeship under his father, as well as how he joins the army and why he became a slave.\n",
            "\n",
            "[2] Kaladin starts training in medicine with his father and assisting him in surgery when he is eight years old. His training is mostly concentrated in, but not limited to, surgery. After joining the army, he gains considerable practice as a field medic, attending to his fellows soldiers injured in combat. He has some level of understanding of pharmacology, as he is able to harvest and extract his own antiseptic from knobweed sap. He also has a basic grasp of neurological disorders like epilepsy.\n",
            "\n",
            "[3] As a Hoed, he is small and extremely wrinkled; Raoden thinks he appears to be \"a thousand years old\". When Kaladin and the others meet him, he has retained the wrinkled skin and also has the bald head common to Elantrians. Kaladin thinks he is Shin, presumably because, as an offworlder, he lacks the epicanthic fold seen in most Rosharans but absent in the Shin.\n",
            "He displays a flair for showmanship; in his role as a fortune seer, he delivers a dramatic speech to entice potential customers into paying for fortunes, and confesses that he quite enjoys doing so. Once he realizes that Kaladin is not there for a fortune, however, he becomes businesslike and helpful, setting the travelers up with transportation and supplies. He's a follower of Shu-Korath, or at least has been heavily exposed to it.\n",
            "\n",
            "[4] Kaladin\n",
            "Kaladin finishes working on Skar, saying that he will be able to walk normally once he heals up. Kaladin then notices that Sadeas is retreating even though the battle seems to be going well, and realizes that the Highprince is betraying Dalinar. Kaladin sees that Sadeas is unharmed, and hears him say that Dalinar's honor would someday get him killed.\n",
            "Dalinar\n",
            "Adolin yells at Dalinar that he knew that Sadeas's betrayal was inevitable, as they fight off waves of Parshendi, and Dalinar agrees in resignation. Adolin refuses to blame his father though, saying that his honor would not make him behave differently, which surprises Dalinar. Dalinar tries to motivate his soldiers with a speech, saying that they will all die with glory and honor intact. Dalinar silently regrets that he will leave Renarin alone to inherit, surrounded by enemies, and says good bye.\n",
            "\n",
            "[5] Vasher, as Zahel, trains Kaladin and is able to understand him, knowing that he is a profound person who asks many questions. Kaladin trusts Vasher enough that he later seeks his advice when he is bothered with the moral decision of letting King Elhokar be killed.\n",
            "Later still, after Kaladin has been relieved of duty due to his battle shock, he seeks out the ardent to talk about his future, and after a sparring match with the man and a discussion about his own thoughts and feelings, Vasher helps Kaladin to begin understanding that he must find his own way rather than relying on what others want of him.\n",
            "\n",
            "Generating answer...\n",
            "\n",
            "Kaladin realizes that Sadeas is betraying Dalinar.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = input(\"Enter your question: \")\n",
        "    results = search(query)\n",
        "\n",
        "    print(\"\\nTop matching chunks:\\n\")\n",
        "    for i, r in enumerate(results, 1):\n",
        "        print(f\"[{i}] {r['text']}\\n\")\n",
        "\n",
        "    print(\"Generating answer...\\n\")\n",
        "    answer = generate_answer(results, query)\n",
        "    print(answer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ba7077c5c064699b894222d65024406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66195108f7e44358bf957758e1a216ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddc309f8cb84347887738050acf8ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d778b919efa40a993784a9ed5e8f9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66195108f7e44358bf957758e1a216ea",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba7077c5c064699b894222d65024406",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "91a4dbdddb22401e918b3ba07c08da7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2d99f519f84cb280214897588ff531": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3c336092af4d609f60cdb3238fdd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be4137738f1c41bd8d68e2f6300d297d",
              "IPY_MODEL_e2888432c11c46579441ccdbf1b26e90",
              "IPY_MODEL_8d778b919efa40a993784a9ed5e8f9e0"
            ],
            "layout": "IPY_MODEL_e3d0155e67f24965b811bf278e59448e"
          }
        },
        "be4137738f1c41bd8d68e2f6300d297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a4dbdddb22401e918b3ba07c08da7e",
            "placeholder": "​",
            "style": "IPY_MODEL_d03f2a1ed5e54b25aaa2e802c15ccd66",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "d03f2a1ed5e54b25aaa2e802c15ccd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2888432c11c46579441ccdbf1b26e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2d99f519f84cb280214897588ff531",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ddc309f8cb84347887738050acf8ab6",
            "value": 0
          }
        },
        "e3d0155e67f24965b811bf278e59448e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
